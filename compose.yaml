# Copyright (c) Humanitarian OpenStreetMap Team
# This file is part of Field-TM.
#
#     Field-TM is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     Field-TM is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with Field-TM.  If not, see <https:#www.gnu.org/licenses/>.
#

name: fmtm

volumes:
  fmtm_data:
  fmtm_db_data:
  fmtm_logs:
  fmtm_images:
  fmtm_tiles:
  central_db_data:
  central_frontend:

networks:
  fmtm-net:
    name: fmtm-local
    ipam:
      driver: default
      config:
        - subnet: 10.20.30.0/24

services:
  proxy:
    image: "bunkerity/bunkerweb-all-in-one:${BUNKERWEB_TAG:-1.6.2-rc1}"
    depends_on:
      # Frontends must be built and available first
      ui:
        condition: service_started
      ui-mapper:
        condition: service_started
      central-ui:
        condition: service_completed_successfully
        required: false
    volumes:
      - central_frontend:/var/www/html/odk.fmtm.localhost:ro
    ports:
      - ${FMTM_DEV_PORT:-7050}:8080
    environment:
      # General
      BUNKERWEB_INSTANCES: proxy:5000
      LOG_LEVEL: notice
      UI_WIZARD: no
      USE_BUNKERNET: no
      DISABLE_DEFAULT_SERVER: yes
      API_WHITELIST_IP: 127.0.0.0/8 10.20.30.0/24
      # Avoid running ModSec rules on internal service calls
      WHITELIST_IP: 10.20.30.0/24
      WHITELIST_URI: http://fmtm.localhost:7050
      MULTISITE: yes
      USE_REVERSE_PROXY: yes
      # Required for electric headers electric-offset, electric-handle, electric-schema, electric-cursor
      KEEP_UPSTREAM_HEADERS: yes
      REVERSE_PROXY_INTERCEPT_ERRORS: no
      ALLOWED_METHODS: OPTIONS|HEAD|GET|POST|PATCH|PUT|DELETE
      USE_REAL_IP: yes
      SERVE_FILES: yes
      USE_BACKUP: no
      USE_METRICS: no
      # USE_ANTIBOT: yes
      USE_LIMIT_CONN: no
      USE_BAD_BEHAVIOR: no
      USE_LIMIT_REQ: no
      USE_MODSECURITY: no
      USE_GZIP: yes
      # On client, brotli is preferred over gzip if both are enabled
      USE_BROTLI: yes
      # Reverse proxy configs
      SERVER_NAME: fmtm.localhost mapper.fmtm.localhost api.fmtm.localhost s3.fmtm.localhost sync.fmtm.localhost odk.fmtm.localhost odkcentral
      fmtm.localhost_REVERSE_PROXY_HOST: http://ui:7051
      fmtm.localhost_MAX_CLIENT_SIZE: 1G
      # We allow accelerometer, camera, fullscreen, geolocation, magnetometer, gyroscope
      fmtm.localhost_PERMISSIONS_POLICY: accelerometer=(self), ambient-light-sensor=(), attribution-reporting=(), autoplay=(), battery=(), bluetooth=(), browsing-topics=(), camera=(self), compute-pressure=(), display-capture=(), encrypted-media=(), execution-while-not-rendered=(), execution-while-out-of-viewport=(), fullscreen=(self), gamepad=(), geolocation=(self), gyroscope=(self), hid=(), identity-credentials-get=(), idle-detection=(), local-fonts=(), magnetometer=(self), microphone=(), midi=(), otp-credentials=(), payment=(), picture-in-picture=(), publickey-credentials-create=(), publickey-credentials-get=(), screen-wake-lock=(), serial=(), speaker-selection=(), storage-access=(), usb=(), web-share=(), window-management=(), xr-spatial-tracking=(), interest-cohort=()
      # Required for vite websockets / live-reload
      fmtm.localhost_REVERSE_PROXY_WS: yes
      mapper.fmtm.localhost_REVERSE_PROXY_HOST: http://ui-mapper:7057
      mapper.fmtm.localhost_MAX_CLIENT_SIZE: 1G
      # Required for vite websockets / live-reload
      mapper.fmtm.localhost_REVERSE_PROXY_WS: yes
      api.fmtm.localhost_REVERSE_PROXY_HOST: http://api:8000
      api.fmtm.localhost_MAX_CLIENT_SIZE: 1G
      # Increase timeout slightly for long project creation requests
      api.fmtm.localhost_REVERSE_PROXY_READ_TIMEOUT: 90s
      s3.fmtm.localhost_REVERSE_PROXY_HOST: http://s3:9000
      s3.fmtm.localhost_MAX_CLIENT_SIZE: 10G
      sync.fmtm.localhost_REVERSE_PROXY_HOST: http://electric:3000
      sync.fmtm.localhost_MAX_CLIENT_SIZE: 1G
      # Expose-Headers are RESPONSE headers the browser is allowed to access
      sync.fmtm.localhost_CORS_EXPOSE_HEADERS: electric-offset,electric-handle,electric-schema,electric-cursor,electric-up-to-date
      odk.fmtm.localhost_REVERSE_PROXY_HOST: http://central:8383
      odk.fmtm.localhost_REVERSE_PROXY_URL: ~ ^/v\d
      # buffer requests, but not responses, so streaming out works
      odk.fmtm.localhost_REVERSE_PROXY_BUFFERING: no
      odk.fmtm.localhost_MAX_CLIENT_SIZE: 1G
      # Service for local development only to facilitate https odkcentral
      odkcentral_REVERSE_PROXY_HOST: http://central:8383
      odkcentral_REVERSE_PROXY_URL: ~ ^/v\d
      odkcentral_REVERSE_PROXY_BUFFERING: no
      odkcentral_MAX_CLIENT_SIZE: 1G
      # Custom cert only for local development
      odkcentral_USE_CUSTOM_SSL: yes
      odkcentral_AUTO_REDIRECT_HTTP_TO_HTTPS: no
      odkcentral_CUSTOM_SSL_CERT_DATA: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUI5RENDQVhtZ0F3SUJBZ0lVWXFyb0dWRVdsK204eU9OY2pUU2pCWThkckN3d0NnWUlLb1pJemowRUF3SXcKRlRFVE1CRUdBMVVFQXd3S2IyUnJZMlZ1ZEhKaGJEQWdGdzB5TkRBM01qTXhNakF6TVRWYUdBOHlNVEkwTURZeQpPVEV5TURNeE5Wb3dGVEVUTUJFR0ExVUVBd3dLYjJSclkyVnVkSEpoYkRCMk1CQUdCeXFHU000OUFnRUdCU3VCCkJBQWlBMklBQktSZmpOQVFzWUI0ekNXckdETHdKNEVIRDRTNW5rL1Z3aG00TmYwN203c0RTai9RTzlYK0JnNjIKeWlMbWVzT1ZMRExHRklpZXZ2aHIrZkxNY0YwUDQwN0FWKytER1o5bXZ6VmNwMVdZMlE5NllpTVVuelM3MWx0RQo4K3BXbFBmanRLT0JoekNCaERBZEJnTlZIUTRFRmdRVWNVekZsNUpWN1dUM045VUhxbmhSRHlWT3ZjY3dId1lEClZSMGpCQmd3Rm9BVWNVekZsNUpWN1dUM045VUhxbmhSRHlWT3ZjY3dEd1lEVlIwVEFRSC9CQVV3QXdFQi96QXgKQmdOVkhSRUVLakFvZ2dwdlpHdGpaVzUwY21Gc2doUXFMbTlrYXk1bWJYUnRMbXh2WTJGc2FHOXpkSWNFQ2hRZQpNakFLQmdncWhrak9QUVFEQWdOcEFEQm1BakVBb2xuOGRubmlQN0dKSEJPQW4rTHVCV0ZhaUY1NHFZRmpTYyt1Clpia1cwY1pyNWw2VnZ6WVlBdGdWbUtOdTB5WWRBakVBMWlvT2JRTERYdDV3S1JPWjV5VUtmbys2T21IbTV1NWkKQU5LUHd2MExqc2ZIYk5hbzJMWnduK0VxTjNtdUpPNXEKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
      odkcentral_CUSTOM_SSL_KEY_DATA: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JRzJBZ0VBTUJBR0J5cUdTTTQ5QWdFR0JTdUJCQUFpQklHZU1JR2JBZ0VCQkRCc21pQjBmUU5hR1VobEdpWnMKNks1YVo1K1hUOVM1cFdlWkhZc05SVXRlK2FRZ1hIK0pTSmpwRnFqRnNLN21abldoWkFOaUFBU2tYNHpRRUxHQQplTXdscXhneThDZUJCdytFdVo1UDFjSVp1RFg5TzV1N0Ewby8wRHZWL2dZT3Rzb2k1bnJEbFN3eXhoU0lucjc0CmEvbnl6SEJkRCtOT3dGZnZneG1mWnI4MVhLZFZtTmtQZW1JakZKODB1OVpiUlBQcVZwVDM0N1E9Ci0tLS0tRU5EIFBSSVZBVEUgS0VZLS0tLS0K
    networks:
      fmtm-net:
        ipv4_address: 10.20.30.50
    restart: "unless-stopped"

  api:
    image: "ghcr.io/hotosm/field-tm/backend:${TAG_OVERRIDE:-debug}"
    build:
      context: src
      dockerfile: backend/Dockerfile
      target: "${TARGET_OVERRIDE:-debug}"
      args:
        APP_VERSION: "${TAG_OVERRIDE:-debug}"
      cache_from:
        - type=registry,ref=ghcr.io/hotosm/field-tm/backend:${TAG_OVERRIDE:-debug}-cache
        - type=gha
    # Uncomment these to debug with a terminal debugger like pdb
    # Then `docker attach fmtm_api` to debug
    # stdin_open: true
    # tty: true
    volumes:
      - fmtm_logs:/opt/logs
      - ./src/backend/pyproject.toml:/opt/pyproject.toml:ro
      - ./src/backend/app:/opt/app:ro
      - ./src/backend/tests:/opt/tests:ro
      - ./src/backend/scheduler:/opt/scheduler:ro
      - ./src/backend/stats:/opt/stats:ro
      # Workspace packages config
      - ./src/backend/packages/osm-fieldwork/osm_fieldwork:/opt/python/lib/python3.12/site-packages/osm_fieldwork:ro
      - ./src/backend/packages/osm-fieldwork/tests:/opt/package_tests/test_osm_fieldwork:ro
      # External package mounts (testing)
      # - ../osm-rawdata/osm_rawdata:/opt/python/lib/python3.12/site-packages/osm_rawdata:ro
      # - ../fmtm-splitter/fmtm_splitter:/opt/python/lib/python3.12/site-packages/fmtm_splitter:ro
    environment:
      DEBUG: ${DEBUG:-True}
    depends_on:
      proxy:
        condition: service_healthy
      fmtm-db:
        condition: service_healthy
      central:
        condition: service_healthy
        required: false
      migrations:
        condition: service_completed_successfully
      s3:
        condition: service_healthy
    env_file:
      - .env
    ports:
      - "7052-7055:8000"
      - "5678-5679:5678"
    networks:
      - fmtm-net
    extra_hosts:
      odkcentral: 10.20.30.50
    restart: "unless-stopped"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/__lbheartbeat__"]
      start_period: 60s
      interval: 10s
      timeout: 5s
      retries: 10
    deploy:
      replicas: ${API_REPLICAS:-1}
      resources:
        limits:
          cpus: "0.9"
          memory: 1500M
        reservations:
          cpus: "0.1"
          memory: 100M

  ui:
    image: "ghcr.io/hotosm/field-tm/frontend:debug"
    build:
      context: src
      additional_contexts:
        - code=src/frontend
      dockerfile: Dockerfile.ui.debug
      target: build
    volumes:
      - ./src/frontend:/app
      - /app/node_modules/
    environment:
      - VITE_API_URL=http://api.${FMTM_DOMAIN}:${FMTM_DEV_PORT:-7050}
    ports:
      - "7051:7051"
    networks:
      - fmtm-net
    restart: "unless-stopped"

  ui-mapper:
    image: "ghcr.io/hotosm/field-tm/frontend:mapper"
    build:
      context: src
      additional_contexts:
        - code=src/mapper
      dockerfile: Dockerfile.ui.debug
      target: init-db
    volumes:
      - ./src/mapper:/app
      - /app/node_modules/
      - /app/.svelte-kit/
      # - ../ui:/app/node_modules/@hotosm/ui:ro
    environment:
      - TEST_PWA=${TEST_PWA:-false}
      - VITE_API_URL=http://api.${FMTM_DOMAIN}:${FMTM_DEV_PORT:-7050}
      - VITE_SYNC_URL=http://sync.${FMTM_DOMAIN}:${FMTM_DEV_PORT:-7050}
      - VITE_S3_URL=http://s3.${FMTM_DOMAIN}:${FMTM_DEV_PORT:-7050}
    ports:
      - "7057:7057"
    networks:
      - fmtm-net
    restart: "unless-stopped"
    command: >
      sh -c "if [ \"$TEST_PWA\" = \"true\" ]; then pnpm run build && pnpm run preview; else pnpm run dev; fi"

  central:
    profiles: ["", "central"]
    image: "ghcr.io/hotosm/field-tm/odkcentral:${ODK_CENTRAL_TAG:-v2025.2.0}"
    build:
      context: odkcentral/api
      args:
        ODK_CENTRAL_TAG: ${ODK_CENTRAL_TAG:-v2025.2.0}
    depends_on:
      proxy:
        condition: service_healthy
      central-db:
        condition: service_healthy
      s3:
        condition: service_healthy
      pyxform:
        condition: service_started
    environment:
      - DOMAIN=${FMTM_ODK_DOMAIN:-odk.fmtm.localhost}:${FMTM_DEV_PORT:-7050}
      - SSL_TYPE=upstream
      - SYSADMIN_EMAIL=${ODK_CENTRAL_USER}
      - SYSADMIN_PASSWD=${ODK_CENTRAL_PASSWD}
      - HTTPS_PORT=${HTTPS_PORT:-443}
      - DB_HOST=${CENTRAL_DB_HOST:-central-db}
      - DB_USER=${CENTRAL_DB_USER:-odk}
      - DB_PASSWORD=${CENTRAL_DB_PASSWORD:-odk}
      - DB_NAME=${CENTRAL_DB_NAME:-odk}
      - DB_SSL=${DB_SSL:-null}
      - EMAIL_FROM=${ODK_CENTRAL_USER}
      - EMAIL_HOST=${EMAIL_HOST:-mail}
      - EMAIL_PORT=${EMAIL_PORT:-25}
      - EMAIL_SECURE=${EMAIL_SECURE:-false}
      - EMAIL_IGNORE_TLS=${EMAIL_IGNORE_TLS:-true}
      - EMAIL_USER=${EMAIL_USER:-''}
      - EMAIL_PASSWORD=${EMAIL_PASSWORD:-''}
      - OIDC_ENABLED=${OIDC_ENABLED:-false}
      - OIDC_ISSUER_URL=${OIDC_ISSUER_URL:-https://getodk.org}
      - OIDC_CLIENT_ID=${OIDC_CLIENT_ID:-xxx}
      - OIDC_CLIENT_SECRET=${OIDC_CLIENT_SECRET:-xxx}
      - SENTRY_ORG_SUBDOMAIN=${SENTRY_ORG_SUBDOMAIN:-o130137}
      - SENTRY_KEY=${SENTRY_KEY:-3cf75f54983e473da6bd07daddf0d2ee}
      - SENTRY_PROJECT=${SENTRY_PROJECT:-1298632}
      - SENTRY_TRACE_RATE=${SENTRY_TRACE_RATE:-100000}
      # Note S3_ENDPOINT is hardcoded here for when we use tunnel config
      - S3_SERVER="http://s3:9000"
      - S3_BUCKET_NAME=${S3_ODK_BUCKET_NAME:-"fmtm-odk-media"}
      - S3_ACCESS_KEY=${S3_ACCESS_KEY}
      - S3_SECRET_KEY=${S3_SECRET_KEY}
    # ports:
    #   - "8383:8383"
    networks:
      - fmtm-net
    restart: "unless-stopped"
    healthcheck:
      test: nc -z localhost 8383 || exit 1
      start_period: 15s
      interval: 10s
      timeout: 5s
      retries: 10

  pyxform:
    image: "ghcr.io/getodk/pyxform-http:v3.0.0"
    networks:
      - fmtm-net
    restart: "unless-stopped"

  central-ui:
    # This service simply builds the frontend to a volume
    # accessible to the proxy, then shuts down
    profiles: ["", "central"]
    image: "ghcr.io/hotosm/field-tm/odkcentral-ui:${ODK_CENTRAL_TAG:-v2025.2.0}"
    build:
      context: odkcentral/ui
      args:
        ODK_CENTRAL_TAG: ${ODK_CENTRAL_TAG:-v2025.2.0}
    volumes:
      - central_frontend:/frontend
    network_mode: none
    restart: "on-failure:2"

  central-webhook:
    profiles: ["", "central"]
    image: "ghcr.io/hotosm/central-webhook:${ODK_WEBHOOK_TAG:-0.3.0}"
    depends_on:
      central:
        condition: service_healthy
    environment:
      CENTRAL_WEBHOOK_DB_URI: postgresql://${CENTRAL_DB_USER:-odk}:${CENTRAL_DB_USER:-odk}@central-db:5432/${CENTRAL_DB_NAME:-odk}?sslmode=disable
      CENTRAL_WEBHOOK_UPDATE_ENTITY_URL: http://api:8000/integrations/webhooks/entity-status
      # CENTRAL_WEBHOOK_REVIEW_SUBMISSION_URL: https://your.domain.com/some/webhook
      CENTRAL_WEBHOOK_API_KEY: qnyE7ev7OWsfMAaX2fm-PuWYnkAUJw2xlyp72FKCH3Q
      # CENTRAL_WEBHOOK_LOG_LEVEL: DEBUG
    networks:
      - fmtm-net
    restart: "unless-stopped"

  s3:
    image: "docker.io/minio/minio:${MINIO_TAG:-RELEASE.2025-01-20T14-49-07Z}"
    depends_on:
      proxy:
        condition: service_started
    environment:
      MINIO_ROOT_USER: ${S3_ACCESS_KEY:-fmtm}
      MINIO_ROOT_PASSWORD: ${S3_SECRET_KEY:-somelongpassword}
      MINIO_VOLUMES: "/mnt/data"
      MINIO_BROWSER: ${MINIO_BROWSER:-off}
    volumes:
      - fmtm_data:/mnt/data
    # ports:
    # - 9000:9000
    # - 9090:9090
    networks:
      - fmtm-net
    command: minio server
    restart: "unless-stopped"
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 5s
      retries: 3
      start_period: 5s
      timeout: 5s

  fmtm-db:
    # Temp workaround until https://github.com/postgis/docker-postgis/issues/216
    image: "ghcr.io/hotosm/postgis:${POSTGIS_TAG:-14-3.5-alpine}"
    volumes:
      - fmtm_db_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_USER=${FMTM_DB_USER:-fmtm}
      - POSTGRES_PASSWORD=${FMTM_DB_PASSWORD:-fmtm}
      - POSTGRES_DB=${FMTM_DB_NAME:-fmtm}
    ports:
      - "5438:5432"
    networks:
      - fmtm-net
    restart: "unless-stopped"
    # Low max_connections for better performance.
    # See https://richyen.com/postgres/2021/09/03/less-is-more-max-connections.html
    # and other sources online. Approx (cores * 4 * replicas)
    # Plus electric-sql defaults to need 20 connections (64+20)
    command: -c 'max_connections=84' -c 'wal_level=logical'
    healthcheck:
      test: pg_isready -U ${FMTM_DB_USER:-fmtm} -d ${FMTM_DB_NAME:-fmtm}
      start_period: 5s
      interval: 10s
      timeout: 5s
      retries: 3

  electric:
    image: "electricsql/electric:${ELECTRIC_TAG:-1.0.12}"
    depends_on:
      proxy:
        condition: service_started
      fmtm-db:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    environment:
      DATABASE_URL: postgresql://${FMTM_DB_USER:-fmtm}:${FMTM_DB_PASSWORD:-fmtm}@${FMTM_DB_HOST:-fmtm-db}/${FMTM_DB_NAME:-fmtm}?sslmode=disable
      # For development we do not need to include auth token security
      ELECTRIC_INSECURE: true
      # OTEL_EXPORT: otlp
      # OTLP_ENDPOINT: https://...
      # ELECTRIC_WRITE_TO_PG_MODE: direct_writes
    networks:
      - fmtm-net
    restart: "unless-stopped"

  central-db:
    profiles: ["", "central"]
    image: "ghcr.io/hotosm/postgis:${POSTGIS_TAG:-14-3.5-alpine}"
    volumes:
      - central_db_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_USER=${CENTRAL_DB_USER:-odk}
      - POSTGRES_PASSWORD=${CENTRAL_DB_PASSWORD:-odk}
      - POSTGRES_DB=${CENTRAL_DB_NAME:-odk}
    ports:
      - "5434:5432"
    networks:
      - fmtm-net
    restart: "unless-stopped"
    # Optimise to a low number of connections, see fmtm-db service
    command: -c 'max_connections=64'
    healthcheck:
      test: pg_isready -U ${CENTRAL_DB_USER:-odk} -d ${CENTRAL_DB_NAME:-odk}
      start_period: 5s
      interval: 10s
      timeout: 5s
      retries: 3

  migrations:
    image: "ghcr.io/hotosm/field-tm/backend:${TAG_OVERRIDE:-debug}"
    depends_on:
      fmtm-db:
        condition: service_healthy
      s3:
        condition: service_healthy
    env_file:
      - .env
    # Hardcode some vars for dev, as not necessarily present in the .env file
    environment:
      # Note S3_ENDPOINT is hardcoded here for when we use tunnel config
      - S3_ENDPOINT=http://s3:9000
      - S3_BUCKET_NAME=${S3_BUCKET_NAME:-"fmtm-data"}
      - S3_BACKUP_BUCKET_NAME=${S3_BACKUP_BUCKET_NAME:-"fmtm-db-backups"}
    networks:
      - fmtm-net
    entrypoint: ["/migrate-entrypoint.sh"]
    restart: "on-failure:2"
    healthcheck:
      test: ["NONE"] # Set the health check test to NONE to disable it

  scheduler:
    image: "ghcr.io/hotosm/field-tm/backend:${TAG_OVERRIDE:-debug}"
    depends_on:
      fmtm-db:
        condition: service_healthy
    env_file:
      - .env
    environment:
      DEBUG: false
    networks:
      - fmtm-net
    entrypoint: ["/bin/sh", "-c"]
    # The approach below allows us to easily switch to Kubernetes CronJob if needed
    command: |
      "
        # Task unlocking every 3hrs
        echo '* */3 * * * /opt/scheduler/unlock_tasks.py' > ./crontab

        # Check inactive users every Sunday 00:00
        echo '0 0 * * 0 /opt/scheduler/inactive_users.py' >> ./crontab

        # Run project stats script every 10 mins
        echo '*/10 * * * * /opt/scheduler/project_stats.py' >> ./crontab

        # Upload and update project submissions to s3 every 6 hours
        echo '0 */6 * * * /opt/scheduler/upload_submissions_to_s3.py' >> ./crontab

        exec /usr/local/bin/supercronic ./crontab
      "
    restart: "unless-stopped"
    # Check the 'supercronic' service is still running
    healthcheck:
      test: ["CMD", "pgrep", "supercronic"]
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 10s
